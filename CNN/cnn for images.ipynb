{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def corr_2d(X,k):\r\n",
    "    h,w=k.shape\r\n",
    "    y=torch.zeros(X.shape[0]-h+1,X.shape[1]-w+1)\r\n",
    "    for i in range(y.shape[0]):\r\n",
    "        for j in range(y.shape[1]):\r\n",
    "            y[i][j]=(X[i:i+h,j:j+w]*k).sum()\r\n",
    "    return y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "X=torch.randint(1, 10, (100,100))\r\n",
    "k=torch.randint(1, 10, (10,10))\r\n",
    "corr_2d(X,k)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[2579., 2622., 2649.,  ..., 2350., 2309., 2401.],\n",
       "        [2670., 2596., 2604.,  ..., 2315., 2490., 2368.],\n",
       "        [2716., 2720., 2725.,  ..., 2217., 2381., 2171.],\n",
       "        ...,\n",
       "        [2561., 2455., 2392.,  ..., 2402., 2429., 2623.],\n",
       "        [2536., 2432., 2471.,  ..., 2382., 2391., 2384.],\n",
       "        [2566., 2465., 2442.,  ..., 2505., 2442., 2556.]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "class Conv2D(nn.Module):\r\n",
    "    def __init__(self,k_size):\r\n",
    "        super().__init__()\r\n",
    "        self.weight=nn.Parameter(torch.rand(k_size[0],k_size[1]))\r\n",
    "        self.bias=nn.Parameter(torch.zeros(1))\r\n",
    "    def forward(self,input):\r\n",
    "        return corr_2d(input,self.weight)+self.bias"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "val=(k.shape[0],k.shape[1])\r\n",
    "conv=Conv2D(val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "conv(X)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[281.7223, 268.7761, 266.1966,  ..., 250.0331, 246.1008, 238.8815],\n",
       "        [270.3250, 263.3986, 257.1867,  ..., 243.8959, 252.3778, 228.7650],\n",
       "        [284.6339, 264.2975, 262.6812,  ..., 232.8015, 244.4619, 229.3676],\n",
       "        ...,\n",
       "        [250.5531, 230.8836, 239.7252,  ..., 254.6026, 245.5952, 240.9799],\n",
       "        [256.0441, 243.6381, 243.2832,  ..., 248.1702, 252.3488, 258.0821],\n",
       "        [267.5214, 258.7990, 254.3589,  ..., 249.0653, 233.3763, 249.0046]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#object detection\r\n",
    "\r\n",
    "Let us take a moment to parse a simple application of a convolutional layer: detecting the edge ofan object in an image by finding the location of the pixel change. First, we construct an “image”of6\u00028pixels. The middle four columns are black (0) and the rest are white (1)\r\n",
    "\r\n",
    "Next, we construct a kernelKwith a height of 1 and a width of 2. When we perform the cross-correlation operation with the input, if the horizontally adjacent elements are the same, the outputis 0. Otherwise, the output is non-zero."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "X=torch.ones(6,8)\r\n",
    "k=torch.tensor([[1.0,-1.0]])\r\n",
    "X[:,2:6]=0\r\n",
    "y=corr_2d(X,k)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "y.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([6, 7])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "#learning a kernel\r\n",
    "conv2d=nn.Conv2d(1,1,kernel_size=(1,2),bias=False)\r\n",
    "X=X.reshape(1,1,6,8)\r\n",
    "y=y.reshape(1,1,6,7)\r\n",
    "lr=3e-2\r\n",
    "optimizer=torch.optim.SGD(conv2d.parameters(),lr=lr)\r\n",
    "loss=nn.MSELoss()\r\n",
    "for i in range(10):\r\n",
    "    y_hat=conv2d(X)\r\n",
    "    l=(y_hat-y)**2\r\n",
    "    optimizer.zero_grad()\r\n",
    "    l.sum().backward()\r\n",
    "    optimizer.step()\r\n",
    "    if (i+1)%2==0:\r\n",
    "        print(f'Iteration {i+1} , loss {l.sum():.3f}')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 2 , loss 15.810\n",
      "Iteration 4 , loss 4.729\n",
      "Iteration 6 , loss 1.644\n",
      "Iteration 8 , loss 0.624\n",
      "Iteration 10 , loss 0.247\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "conv2d.weight.data.reshape((1,2))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 1.0368, -0.9352]])"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The convolution operation is very similar to the cross-correlation operation but has a slight difference. In Convolution operation, the kernel is first flipped by an angle of 180 degrees and is then applied to the image. The fundamental property of convolution is that convolving a kernel with a discrete unit impulse yields a copy of the kernel at the location of the impulse.\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "The Basic difference between Correlation and convolution is :-\r\n",
    "Correlation is measurement of the similarity between two signals/sequences.\r\n",
    "Convolution is measurement of effect of one signal on the other signal."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "X"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[0.1767, 0.9331, 0.1084, 0.9520, 0.7184, 0.4365, 0.1569, 0.8390],\n",
       "          [0.8747, 0.1435, 0.1686, 0.4194, 0.6186, 0.1667, 0.3601, 0.7520],\n",
       "          [0.0444, 0.4910, 0.9677, 0.9051, 0.0122, 0.4588, 0.6456, 0.4575],\n",
       "          [0.8757, 0.4201, 0.5241, 0.4255, 0.5034, 0.2647, 0.8301, 0.1406],\n",
       "          [0.6907, 0.5136, 0.0228, 0.5339, 0.7769, 0.7910, 0.0781, 0.5106],\n",
       "          [0.3486, 0.4837, 0.6540, 0.5129, 0.2657, 0.7830, 0.0229, 0.8276]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "val[length//2:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'39'"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "arr=[3,1,2,4]\r\n",
    "t=7\r\n",
    "arr=sorted(arr)\r\n",
    "triplets=[]\r\n",
    "for i in range(len(arr)):\r\n",
    "    j=i+1\r\n",
    "    k=len(arr)-1\r\n",
    "    while j<k and arr[i]+arr[j]<t:\r\n",
    "        if arr[i]+arr[j]+arr[k]<=t:\r\n",
    "            triplets+=[[arr[i],arr[j],arr[val]] for val in range(j+1,k+1)]\r\n",
    "            triplets\r\n",
    "            j+=1\r\n",
    "        else:\r\n",
    "            k-=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "len(triplets)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "[1,2,3,4,5]\r\n",
    "t=8"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "triplets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[1, 2, 5], [1, 3, 4]]"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "db9dc6d4cc6f4eb1b63b50567ef0052daa9d3b021329b4caf8b52314177c6ded"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}