{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "from torch.nn import functional as F\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "X=torch.rand(5,200)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "X.reshape(-1,).shape[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "class MLP(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.hidden=nn.Linear(X.shape[1],100)\r\n",
    "        self.out=nn.Linear(100,10)\r\n",
    "\r\n",
    "    def forward(self,X):\r\n",
    "        out=self.hidden(X)\r\n",
    "        out=self.out(out)\r\n",
    "        return out\r\n",
    "net=MLP()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "net(X)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-4.5019e-04, -1.9895e-01, -4.1760e-02,  5.1080e-02,  1.7279e-01,\n",
       "          2.1435e-01, -7.3944e-02,  2.5835e-01, -4.5897e-01, -5.1597e-01],\n",
       "        [ 4.6677e-02, -4.0500e-02, -1.5627e-02,  6.4855e-02,  1.7886e-01,\n",
       "          1.4486e-01,  5.4419e-02,  3.9130e-01, -9.1697e-02, -4.7719e-01],\n",
       "        [-1.3612e-01, -2.0687e-01, -5.2615e-02,  1.3820e-01,  1.9513e-01,\n",
       "          1.5252e-01, -6.3659e-02,  1.8953e-01, -2.4068e-01, -5.1482e-01],\n",
       "        [-5.5643e-03, -8.4100e-02,  9.7271e-02,  1.7865e-01,  1.5145e-01,\n",
       "          1.9557e-01,  6.5524e-02,  3.2043e-01, -2.2445e-01, -8.6881e-02],\n",
       "        [ 2.5261e-03, -4.0266e-02,  1.6192e-01,  5.7669e-02,  6.6004e-02,\n",
       "          2.2133e-01, -8.6791e-02,  3.9729e-01, -3.9761e-01, -5.1552e-01]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#Sequential Block\r\n",
    "\r\n",
    "class sequential(nn.Module):\r\n",
    "    def __init__(self,*args):\r\n",
    "        super().__init__()\r\n",
    "        for idx ,module in enumerate(args):\r\n",
    "            self._modules[str(idx)]=module\r\n",
    "        \r\n",
    "    def forward(self,X):\r\n",
    "        for block in self._modules.values():\r\n",
    "            X=block(X)\r\n",
    "\r\n",
    "        return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "#relu --> x=max(0,x)\r\n",
    "net=sequential(nn.Linear(X.shape[1],100)\r\n",
    "               ,nn.ReLU()\r\n",
    "               , nn.Linear(100,10) )\r\n",
    "               "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "net(X)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.1186,  0.1260, -0.0815,  0.2744, -0.1318, -0.1365, -0.0145, -0.2494,\n",
       "         -0.0837,  0.0326],\n",
       "        [ 0.0327,  0.0269, -0.0861,  0.2140, -0.0985, -0.0449, -0.0617, -0.0958,\n",
       "         -0.1022, -0.0164],\n",
       "        [-0.0172,  0.0048, -0.0506,  0.3520, -0.1165, -0.1671, -0.0756, -0.2014,\n",
       "         -0.0512, -0.0450],\n",
       "        [-0.0075,  0.0756, -0.0488,  0.3032, -0.1754, -0.1486, -0.1293, -0.0816,\n",
       "         -0.1936, -0.0091],\n",
       "        [ 0.0096,  0.0401,  0.0316,  0.2533, -0.1067, -0.0761, -0.0568, -0.2256,\n",
       "         -0.0667, -0.0403]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "db9dc6d4cc6f4eb1b63b50567ef0052daa9d3b021329b4caf8b52314177c6ded"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}