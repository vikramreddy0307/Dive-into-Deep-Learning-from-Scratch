{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "from torch import functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "torch.save([1,2,3],'sample')\r\n",
    "#x,*y=torch.load('sample')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "torch.load('sample')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class MLP(nn.Module):\r\n",
    "    def __init__(self,inp,out):\r\n",
    "        super().__init__()\r\n",
    "        self.hidden=nn.Linear(inp,100)\r\n",
    "        self.output=nn.Linear(100,out)\r\n",
    "\r\n",
    "    def forward(self,X):\r\n",
    "        return self.output(self.hidden(X))\r\n",
    "X=torch.rand(20,40)\r\n",
    "mlp=MLP(X.shape[1],4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "mlp(X)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0262,  0.0755,  0.0100, -0.2003],\n",
       "        [-0.0939,  0.1170,  0.0023, -0.1048],\n",
       "        [-0.0156,  0.0854, -0.0961, -0.0451],\n",
       "        [-0.0245,  0.1283, -0.0559, -0.0979],\n",
       "        [ 0.0823,  0.1685,  0.0004, -0.0433],\n",
       "        [-0.0436,  0.1487, -0.1331, -0.0797],\n",
       "        [-0.1974, -0.0297, -0.0534, -0.0904],\n",
       "        [ 0.1479,  0.0772, -0.0700,  0.0047],\n",
       "        [-0.0741,  0.1196, -0.0597, -0.1230],\n",
       "        [-0.0371,  0.0685,  0.0728, -0.2414],\n",
       "        [ 0.0680,  0.2262, -0.0767, -0.0692],\n",
       "        [-0.0162,  0.0861, -0.0844, -0.1389],\n",
       "        [-0.0697,  0.0732, -0.0663, -0.0532],\n",
       "        [-0.0589,  0.1809,  0.0007, -0.1672],\n",
       "        [-0.1238,  0.1834, -0.0145, -0.1695],\n",
       "        [-0.2688,  0.1709, -0.0535, -0.2369],\n",
       "        [-0.0946, -0.0067,  0.0348, -0.2858],\n",
       "        [ 0.0973,  0.1824, -0.0879, -0.1052],\n",
       "        [-0.0388,  0.1627, -0.0472, -0.2041],\n",
       "        [-0.0851, -0.0783, -0.0490, -0.1380]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "mlp.state_dict()['hidden.weight']\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.0114,  0.0329,  0.1264,  ...,  0.0503,  0.0674, -0.1545],\n",
       "        [-0.0255, -0.1567, -0.1466,  ...,  0.0617, -0.0310,  0.0956],\n",
       "        [-0.0862,  0.1426,  0.0321,  ..., -0.0929, -0.1542,  0.0736],\n",
       "        ...,\n",
       "        [-0.1523,  0.0114, -0.0294,  ...,  0.0353, -0.0741,  0.1577],\n",
       "        [-0.1484, -0.0328, -0.1318,  ..., -0.0271,  0.0238,  0.0338],\n",
       "        [-0.0711,  0.0391,  0.0836,  ..., -0.1271, -0.0544, -0.0308]])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "torch.save(mlp.state_dict(),'mlp-params')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "clone=MLP(X.shape[1],4)\r\n",
    "clone.load_state_dict(torch.load('mlp-params'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "clone.state_dict()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[-0.0114,  0.0329,  0.1264,  ...,  0.0503,  0.0674, -0.1545],\n",
       "                      [-0.0255, -0.1567, -0.1466,  ...,  0.0617, -0.0310,  0.0956],\n",
       "                      [-0.0862,  0.1426,  0.0321,  ..., -0.0929, -0.1542,  0.0736],\n",
       "                      ...,\n",
       "                      [-0.1523,  0.0114, -0.0294,  ...,  0.0353, -0.0741,  0.1577],\n",
       "                      [-0.1484, -0.0328, -0.1318,  ..., -0.0271,  0.0238,  0.0338],\n",
       "                      [-0.0711,  0.0391,  0.0836,  ..., -0.1271, -0.0544, -0.0308]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([ 0.1169, -0.0030,  0.1291,  0.0432,  0.1412,  0.0682,  0.0129,  0.0167,\n",
       "                       0.0455, -0.0320,  0.0596,  0.0442,  0.1100,  0.1285, -0.0406, -0.0691,\n",
       "                      -0.0962, -0.1125, -0.0243,  0.0440,  0.0859, -0.1517,  0.0319,  0.1199,\n",
       "                      -0.1033,  0.0704, -0.0338,  0.0428,  0.0471, -0.0376, -0.0718, -0.1216,\n",
       "                       0.0098, -0.1440, -0.1410,  0.0052, -0.0869,  0.0949,  0.0666,  0.0747,\n",
       "                      -0.0642,  0.0831,  0.0877, -0.0812,  0.0958, -0.1498,  0.0957,  0.0835,\n",
       "                       0.1256,  0.0576,  0.0670, -0.0253, -0.1020,  0.0881, -0.1346,  0.0391,\n",
       "                       0.0074, -0.0459, -0.1431, -0.1085, -0.1162, -0.1193, -0.0613, -0.1402,\n",
       "                      -0.0979,  0.0398,  0.0617,  0.0575, -0.0239, -0.1525,  0.1160,  0.1387,\n",
       "                       0.0132, -0.0512,  0.0702,  0.1105, -0.0545,  0.0476, -0.1482, -0.0008,\n",
       "                      -0.0834,  0.1164,  0.0612, -0.1413, -0.0475, -0.0478,  0.0561,  0.0162,\n",
       "                       0.0791,  0.0395,  0.1180, -0.1344, -0.1121, -0.0683, -0.1325, -0.0417,\n",
       "                       0.0462,  0.0145, -0.1056,  0.0246])),\n",
       "             ('output.weight',\n",
       "              tensor([[ 9.4204e-04, -1.9273e-02, -6.3205e-02, -2.7162e-02,  5.4695e-02,\n",
       "                       -9.3571e-02, -2.1870e-02,  9.7277e-02, -1.3836e-02, -4.1045e-02,\n",
       "                       -8.6647e-02, -2.0791e-03, -2.1299e-02,  4.2977e-02, -1.5586e-02,\n",
       "                        8.5500e-03,  2.0853e-02, -4.2848e-02, -8.4572e-02,  9.0219e-02,\n",
       "                       -7.0805e-02,  1.6566e-02,  3.9552e-02, -2.6650e-03, -3.9573e-02,\n",
       "                        7.2785e-02,  7.7316e-02,  7.9189e-02, -8.6907e-03,  8.7359e-02,\n",
       "                        4.9345e-02, -9.2490e-02,  3.7804e-02, -1.4336e-02,  2.0584e-02,\n",
       "                       -3.3350e-02, -3.9438e-02, -3.1749e-02,  9.6300e-02,  2.8518e-02,\n",
       "                       -6.0519e-02, -1.6412e-03,  1.7100e-02,  8.6432e-02, -8.2270e-02,\n",
       "                       -9.6411e-02, -4.7632e-02,  9.1946e-03,  8.2659e-02, -2.7522e-02,\n",
       "                       -3.6258e-02, -7.9418e-02,  9.9631e-02,  1.7982e-02,  3.2834e-02,\n",
       "                       -1.7896e-03, -1.7733e-02, -4.3246e-03,  8.4908e-02, -4.3125e-02,\n",
       "                       -5.9275e-02,  9.1372e-02, -3.4292e-02,  2.9862e-02,  8.4164e-02,\n",
       "                        9.5010e-02,  6.9423e-02,  7.9500e-02,  4.5416e-02,  4.2174e-02,\n",
       "                       -5.5738e-02,  4.3952e-02, -2.2766e-02,  3.0532e-03, -5.8004e-02,\n",
       "                        8.5916e-02, -4.5998e-02, -1.1114e-02, -8.0814e-02,  8.4676e-02,\n",
       "                       -3.5769e-02,  1.5044e-02, -1.4625e-02,  6.6494e-02,  8.9024e-02,\n",
       "                        9.2701e-02,  3.9410e-02, -3.8752e-02,  4.6397e-02,  5.9163e-02,\n",
       "                        8.0458e-02, -7.5121e-02, -8.6724e-02, -6.1373e-02, -4.2547e-02,\n",
       "                       -6.2787e-02,  1.8257e-02, -8.4353e-02, -1.4164e-02,  8.8183e-03],\n",
       "                      [ 1.7637e-02, -2.0505e-02, -1.2725e-02, -1.2554e-03, -2.6531e-02,\n",
       "                        9.2328e-02,  3.2552e-02, -4.2417e-02,  2.1259e-02,  9.0879e-02,\n",
       "                       -6.0631e-02,  3.0884e-02, -5.2595e-02,  8.2981e-02, -7.9175e-02,\n",
       "                        2.4879e-02, -6.5422e-02,  9.4327e-02, -4.7239e-02,  4.2831e-02,\n",
       "                        6.0416e-02,  6.4009e-02, -4.3423e-02,  3.7546e-02, -3.1839e-03,\n",
       "                        4.7080e-02, -3.0059e-02, -5.6818e-02, -5.9977e-02, -3.4693e-02,\n",
       "                       -3.2813e-02,  3.7464e-02,  1.7766e-02, -3.8935e-02, -6.8637e-04,\n",
       "                       -6.6805e-02,  2.6579e-02, -1.7386e-02,  3.8365e-02,  7.4742e-02,\n",
       "                        7.3462e-03,  6.2708e-02, -9.2873e-02,  3.4113e-03,  6.0302e-03,\n",
       "                       -5.3855e-02,  7.0447e-03,  5.5215e-02,  4.6233e-02,  1.1639e-02,\n",
       "                        1.1124e-02,  9.0715e-02,  4.4588e-02, -2.8356e-02,  1.2874e-02,\n",
       "                       -1.5864e-02, -7.8921e-02, -8.1674e-02,  1.0427e-02, -9.2460e-02,\n",
       "                       -6.5973e-02,  6.6427e-02,  7.3968e-02, -7.3588e-02,  5.4131e-02,\n",
       "                        6.8510e-02,  6.1196e-03,  8.2571e-02, -5.4758e-02,  4.2954e-02,\n",
       "                       -7.2758e-02,  1.6430e-02,  7.5596e-02,  4.0470e-02,  7.5622e-02,\n",
       "                        4.7188e-02, -7.0169e-02, -4.1750e-02,  6.8063e-02, -8.6945e-02,\n",
       "                       -3.8621e-02, -9.5607e-02,  3.3329e-03, -1.9999e-04, -9.2880e-02,\n",
       "                        7.8432e-02,  2.6233e-02, -6.7247e-02,  4.2443e-03,  3.6025e-03,\n",
       "                        8.0657e-02,  6.4096e-02,  4.6087e-02, -1.5140e-02,  8.0093e-02,\n",
       "                        7.2264e-03, -9.7912e-02, -6.5441e-02, -3.1994e-02, -9.3734e-02],\n",
       "                      [-2.0521e-02, -9.3223e-02, -3.9065e-02,  4.7401e-02, -2.6188e-02,\n",
       "                       -2.9264e-02,  6.1783e-02, -3.0427e-02,  7.2735e-02, -9.2033e-02,\n",
       "                        9.9933e-02,  9.6087e-03,  8.8666e-02, -3.7313e-02, -1.1825e-02,\n",
       "                       -5.8729e-02,  7.5032e-03, -9.1007e-02,  9.9035e-02, -3.9214e-02,\n",
       "                        2.6820e-02, -7.6018e-02,  3.8625e-02, -7.7787e-02,  5.1411e-02,\n",
       "                        8.2097e-02, -1.8737e-02,  5.3333e-02, -4.5686e-02, -4.7267e-02,\n",
       "                       -9.9918e-02,  9.4427e-03, -9.3129e-02,  7.5908e-02,  2.2326e-02,\n",
       "                        2.4662e-02, -1.9546e-02, -6.9613e-02, -2.8292e-02,  6.0065e-02,\n",
       "                       -3.8715e-02, -8.5211e-02,  2.9683e-02, -1.6744e-02, -7.6114e-02,\n",
       "                       -7.0854e-02, -3.5327e-02, -7.5424e-02, -3.4373e-02, -4.6136e-02,\n",
       "                        5.9935e-03, -1.0375e-02, -8.1309e-02, -1.6756e-02, -5.6744e-02,\n",
       "                        6.7029e-03,  8.0065e-02,  8.6902e-02,  4.1234e-02, -4.9741e-02,\n",
       "                       -6.1453e-02,  3.1374e-05, -4.1550e-02,  6.8291e-02,  7.1583e-03,\n",
       "                       -9.4879e-02,  6.3498e-02,  4.8793e-02,  5.8032e-02,  9.4688e-02,\n",
       "                       -4.1662e-02, -9.3833e-02,  5.5141e-02, -7.7112e-02,  6.0115e-02,\n",
       "                       -1.2908e-02, -7.3749e-02, -4.3892e-02,  7.6111e-02,  5.9091e-03,\n",
       "                        7.7465e-02,  3.4850e-03,  1.2069e-02, -4.6435e-02, -4.5364e-02,\n",
       "                        1.4445e-02, -5.6282e-02, -3.1161e-03,  8.9653e-02,  3.4876e-02,\n",
       "                       -4.6166e-02, -5.5206e-02, -7.8524e-02, -4.4905e-02, -6.3355e-02,\n",
       "                       -2.7511e-02,  5.1978e-02, -3.0351e-02,  1.0350e-02, -9.4817e-02],\n",
       "                      [-8.8149e-02, -5.2845e-03,  6.7026e-02, -9.5949e-02,  8.4113e-02,\n",
       "                       -6.1693e-03, -9.8489e-02, -9.4823e-02, -5.7655e-03, -7.1932e-02,\n",
       "                        9.8638e-02,  4.6272e-02, -5.0110e-02,  9.3778e-02,  6.5058e-02,\n",
       "                       -6.2881e-02,  4.3450e-02, -7.9067e-02, -3.6414e-02,  9.8730e-02,\n",
       "                        4.8177e-02, -2.6993e-02, -1.2440e-02,  4.3790e-02, -6.1598e-03,\n",
       "                        3.8513e-02, -1.2288e-02,  1.1496e-03,  2.6375e-06, -6.8189e-02,\n",
       "                       -5.7736e-02, -1.6832e-02,  8.1487e-02, -3.4301e-02, -8.7710e-02,\n",
       "                       -5.0947e-02,  1.7258e-03, -7.8850e-02,  9.2249e-02,  4.8671e-03,\n",
       "                        1.7571e-03, -5.3798e-02,  9.1515e-02,  6.8866e-02,  1.3783e-02,\n",
       "                       -5.3092e-02,  8.9356e-02, -1.4588e-02,  1.8470e-02,  8.6485e-02,\n",
       "                       -3.7635e-02, -9.2609e-02, -1.4732e-02, -4.8057e-02,  4.8754e-02,\n",
       "                        1.9023e-02, -3.6865e-02,  5.1775e-02,  5.6608e-02, -3.1708e-02,\n",
       "                        3.2734e-02,  5.3113e-02, -9.2228e-02, -3.0855e-02,  4.4095e-02,\n",
       "                        1.9448e-02,  1.8096e-02, -7.3748e-02,  8.3057e-02, -3.5386e-02,\n",
       "                        3.6063e-02,  1.2579e-02, -7.2855e-03, -2.2381e-02,  4.2732e-03,\n",
       "                       -4.6001e-02, -4.9664e-02,  7.9770e-02, -3.8666e-02,  3.7565e-02,\n",
       "                       -2.4263e-02, -1.1003e-02, -5.0393e-02,  4.7700e-02, -6.6332e-02,\n",
       "                       -7.8076e-02,  3.6438e-02,  3.3464e-02,  9.5431e-02, -6.8614e-02,\n",
       "                        2.2799e-02,  4.3469e-02,  2.1663e-02,  4.4364e-02,  3.2515e-02,\n",
       "                        6.4072e-02,  5.0712e-02,  2.8996e-02,  4.3811e-02, -8.2790e-03]])),\n",
       "             ('output.bias', tensor([-0.0201, -0.0834, -0.0523, -0.0158]))])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "db9dc6d4cc6f4eb1b63b50567ef0052daa9d3b021329b4caf8b52314177c6ded"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}