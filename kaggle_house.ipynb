{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "n = 6\r\n",
    "connections = [[0,1],[1,3],[2,3],[4,0],[4,5]]\r\n",
    "def minReorder( n: int, connections):\r\n",
    "    adj=[[] for i in range(n)]\r\n",
    "    vis=[False for i in range(n)]\r\n",
    "    ans=0\r\n",
    "    hset=set()\r\n",
    "    for i in range(len(connections)):\r\n",
    "        adj[connections[i][0]].append(connections[i][1])\r\n",
    "        adj[connections[i][1]].append(connections[i][0])\r\n",
    "        hset.add(tuple(connections[i]))\r\n",
    "    vis[0]=True\r\n",
    "    dfs(0,adj,hset,vis)\r\n",
    "    return ans\r\n",
    "    def dfs(self,node,adj,hset,vis):\r\n",
    "        for it in adj[node]:\r\n",
    "            if not vis[it] and (node,it) in hset:\r\n",
    "                self.ans+=1\r\n",
    "            if not vis[it]:\r\n",
    "                vis[it]=True\r\n",
    "                self.dfs(it,adj,hset,vis)\r\n",
    "        return\r\n",
    "                "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import numpy as np\r\n",
    "a = [[11,2,4],[4,5,6],[10,8,-12]]\r\n",
    "b = np.asarray(a)\r\n",
    "print('Antidiagonal (sum): ', np.trace(b))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Antidiagonal (sum):  4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "def solve( A):\r\n",
    "        cnt=0\r\n",
    "        while A>1:\r\n",
    "            if A%2==0:\r\n",
    "                cnt+=1\r\n",
    "            else:\r\n",
    "                break\r\n",
    "            A=A//2\r\n",
    "            # print(A)\r\n",
    "        return cnt\r\n",
    "solve(18)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "def xorSequence(l, r):\r\n",
    "    A=[0,1]\r\n",
    "    i=3\r\n",
    "    while r+1>len(A):\r\n",
    "        A+=[i,0,i+1,1]\r\n",
    "        i+=4\r\n",
    "    print(len(A))\r\n",
    "    val=0\r\n",
    "    for i in range(l,r+1):\r\n",
    "        val^=A[i]\r\n",
    "    return val\r\n",
    "xorSequence(4, 6)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "7//3\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "n,m,a=6,6,4\r\n",
    "if a==n and a==m:\r\n",
    "    print(1)\r\n",
    "else:\r\n",
    "    remain=(n-a)\r\n",
    "    total=0\r\n",
    "    if remain%a>0:\r\n",
    "        length=remain//2+1\r\n",
    "    else:\r\n",
    "        length=remain//2\r\n",
    "    remain=(m-a)\r\n",
    "    if remain%a>0:\r\n",
    "        width=remain//2+1\r\n",
    "    else:\r\n",
    "        width=remain//2\r\n",
    "    print(length*width)\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import torch\r\n",
    "from torch import nn\r\n",
    "# from d2l import torch as d2l"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train=pd.read_csv('train.csv')\r\n",
    "test=pd.read_csv('test.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "all_features=pd.concat((train.iloc[:,1:-1],test.iloc[:,1:]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "all_features.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2919, 79)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "numeric_cols=all_features.dtypes[all_features.dtypes!='object'].index\r\n",
    "all_features[numeric_cols]=all_features[numeric_cols].apply(lambda x:(x-x.mean())/x.std())\r\n",
    "all_features.fillna(0,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# `Dummy_na=True` considers \"na\" (missing value) as a valid feature value, and\r\n",
    "# creates an indicator feature for it\r\n",
    "all_features=pd.get_dummies(all_features,dummy_na=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_size=len(train)\r\n",
    "train_features=torch.tensor(all_features[:train_size].values,dtype=torch.float32)\r\n",
    "\r\n",
    "test_features=torch.tensor(all_features[train_size:].values,dtype=torch.float32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "train_labels=torch.tensor(train.SalePrice.values.reshape(-1,1),dtype=torch.float32)\r\n",
    "train_labels=torch.tensor(train.SalePrice.values.reshape(-1,1),dtype=torch.float32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "\r\n",
    "inp_shape=train_features.shape[1]\r\n",
    "class Network(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(Network,self).__init__()\r\n",
    "        self.net=nn.Linear(inp_shape,1)\r\n",
    "        \r\n",
    "\r\n",
    "    def forward(self,x):\r\n",
    "        out=self.net(x)\r\n",
    "        return out\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "def train(model,num_epochs,train_iter,train_features,train_labels,test_features,test_labels):\r\n",
    "    train_ls=[]\r\n",
    "    test_ls=[]\r\n",
    "    \r\n",
    "    for epoch in range(num_epochs):\r\n",
    "        model.train()\r\n",
    "        for X,y in train_iter:\r\n",
    "            predictions=model(X)\r\n",
    "            l=loss(predictions,y)\r\n",
    "            optim.zero_grad()\r\n",
    "            l.backward()\r\n",
    "            optim.step()\r\n",
    "        train_ls.append(log_rmse(model,train_features,train_labels))\r\n",
    "        \r\n",
    "        if test_labels!=None:\r\n",
    "            test_ls.append(log_rmse(model,test_features,test_labels))\r\n",
    "            \r\n",
    "\r\n",
    "    return train_ls,test_ls,test_features,test_labels\r\n",
    "\r\n",
    "        \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "def get_k_fold(k,i,X,y):\r\n",
    "    assert k>1 and i<=k\r\n",
    "    X_train,y_train=None,None\r\n",
    "    fold_size=len(X)//k\r\n",
    "    \r\n",
    "    for j in range(k):\r\n",
    "        idx=slice(j*fold_size,(j+1)*fold_size)\r\n",
    "        if j==i:\r\n",
    "            X_valid,y_valid=X[idx,:],y[idx]\r\n",
    "        else:\r\n",
    "            if X_train!=None:\r\n",
    "                X_train,y_train=torch.cat([X_train,X[idx,:]],0),torch.cat([y_train,y[idx]],0)\r\n",
    "            else:\r\n",
    "                X_train,y_train=X[idx,:],y[idx]\r\n",
    "                # print(X_train.shape)\r\n",
    "    return X_train,y_train,X_valid,y_valid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "def k_fold_training(k\r\n",
    "            \r\n",
    "            ,train_features\r\n",
    "            ,train_labels\r\n",
    "            ,test_features\r\n",
    "            ,model\r\n",
    "            ,num_epochs\r\n",
    "            ,loss\r\n",
    "            ):\r\n",
    "\r\n",
    "        assert k>=1\r\n",
    "        train_log_loss_sum,valid_log_loss_sum=0,0\r\n",
    "        for i in range(k):\r\n",
    "                X_train,y_train,X_valid,y_valid=get_k_fold(k,i,train_features,train_labels)\r\n",
    "                \r\n",
    "                train_loader=TensorDataset(X_train,y_train)\r\n",
    "                train_iter=DataLoader(train_loader, batch_size=64, shuffle=False, sampler=None,\r\n",
    "           batch_sampler=None )\r\n",
    "                train_log_loss,valid_log_loss,test_features,test_labels=train(\r\n",
    "                        model\r\n",
    "                        ,num_epochs\r\n",
    "                        ,train_iter\r\n",
    "                        ,X_train\r\n",
    "                        ,y_train\r\n",
    "                        ,X_valid\r\n",
    "                        ,y_valid\r\n",
    "                                        )\r\n",
    "              \r\n",
    "                #extracting the final epoch loss in each k_fold_iteration\r\n",
    "                train_log_loss_sum+=train_log_loss[-1]\r\n",
    "                valid_log_loss_sum+=valid_log_loss[-1]\r\n",
    "                print(f\"fold iteration {i:.0f} --> training log loss {train_log_loss[-1]:.2f} -->validation log loss  {valid_log_loss[-1]:.2f}\")\r\n",
    "                \r\n",
    "        print(f'Num of folds {k:.0f} training loss {train_log_loss_sum/k:.3f} validation loss {valid_log_loss_sum/k:.3f}')\r\n",
    "        \r\n",
    "                \r\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "from torch.utils.data import Dataset,TensorDataset,DataLoader\r\n",
    "# train_loader=TensorDataset(train_features,train_labels)\r\n",
    "# train_iter=DataLoader(train_loader, batch_size=100, shuffle=False, sampler=None,\r\n",
    "#            batch_sampler=None )\r\n",
    "train_features.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1460, 354])"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "num_epochs=100\r\n",
    "model=Network()\r\n",
    "loss=nn.MSELoss()\r\n",
    "learning_rate=5\r\n",
    "weight_decay=0\r\n",
    "optim=torch.optim.Adam(model.parameters(),lr=learning_rate,weight_decay=weight_decay)\r\n",
    "def log_rmse(model,features,labels):\r\n",
    "    model.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        clipped_pred=torch.clamp(model(features),1,float('inf'))\r\n",
    "        rmse=torch.sqrt(loss(torch.log(clipped_pred),torch.log(labels)))\r\n",
    "    return rmse.item()\r\n",
    "    \r\n",
    "k_fold_training(5\r\n",
    "                ,train_features\r\n",
    "                ,train_labels\r\n",
    "                ,test_features\r\n",
    "                ,model\r\n",
    "                ,num_epochs\r\n",
    "                ,loss\r\n",
    "                \r\n",
    "                )\r\n",
    "                    \r\n",
    "                    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 torch.Size([292, 354]) torch.Size([292, 1])\n",
      "fold iteration 0 --> training log loss 0.17 -->validation log loss  0.16\n",
      "1 torch.Size([292, 354]) torch.Size([292, 1])\n",
      "fold iteration 1 --> training log loss 0.14 -->validation log loss  0.15\n",
      "2 torch.Size([292, 354]) torch.Size([292, 1])\n",
      "fold iteration 2 --> training log loss 0.13 -->validation log loss  0.14\n",
      "3 torch.Size([292, 354]) torch.Size([292, 1])\n",
      "fold iteration 3 --> training log loss 0.13 -->validation log loss  0.13\n",
      "4 torch.Size([292, 354]) torch.Size([292, 1])\n",
      "fold iteration 4 --> training log loss 0.12 -->validation log loss  0.15\n",
      "Num of folds 5 training loss 0.138 validation loss 0.144\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "round(val,2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "38.75"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "torch.cat([torch.rand((3,2)),],)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.7231, 0.0120],\n",
       "        [0.1749, 0.6874],\n",
       "        [0.0824, 0.3189]])"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.emp"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "db9dc6d4cc6f4eb1b63b50567ef0052daa9d3b021329b4caf8b52314177c6ded"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}